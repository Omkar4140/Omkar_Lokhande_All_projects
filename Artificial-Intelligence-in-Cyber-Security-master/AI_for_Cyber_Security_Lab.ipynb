{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Lab 1: Introduction to Jupyter Notebooks & Basic AI in Cybersecurity\n",
        "\n",
        "AIM: Logistic Regression for malware detection."
      ],
      "metadata": {
        "id": "ccf-WZ262TaC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYKmoaO92DKM",
        "outputId": "cc07ed52-6e21-4be0-b770-822f4e292a05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.96\n"
          ]
        }
      ],
      "source": [
        "# Lab 1: Malware Detection with Logistic Regression\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "# Load dataset (Example: CSV with file features and labels)\n",
        "\n",
        "# Load data\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/AI in CS/pe_section_headers.csv\")\n",
        "X = data[['size', 'entropy']]\n",
        "y = data['is_malicious']\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "# Train model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "# Evaluate\n",
        "predictions = model.predict(X_test)\n",
        "print(f\"Accuracy: {accuracy_score(y_test, predictions):.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lab 2: Spam Detection using Perceptrons\n",
        "\n",
        "AIM: Classify emails using a perceptron.\n"
      ],
      "metadata": {
        "id": "GEoQWGIC6NQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lab 2: Spam Detection with Perceptron\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# Sample data (replace with SpamAssassin dataset)\n",
        "emails = [\"Get free cash now!\", \"Meeting at 3 PM\", \"Win a prize!\"]\n",
        "labels = [1, 0, 1] # 1=spam, 0=ham\n",
        "# Text vectorization\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(emails)\n",
        "# Train\n",
        "clf = Perceptron()\n",
        "clf.fit(X, labels)\n",
        "# Test\n",
        "test_email = [\"Free lottery\"]\n",
        "print(\"Spam\" if clf.predict(vectorizer.transform(test_email))[0] == 1 else \"Ham\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ao6vbM26PeF",
        "outputId": "d685278f-3b80-4857-c68c-9212a7848e99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lab 3: Phishing Detection with Logistic Regression & Decision Trees\n",
        "\n",
        "AIM: Detect phishing URLs."
      ],
      "metadata": {
        "id": "vZXuKM176Tbh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lab 3: Phishing URL Detection\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# Example features: [url_length, num_special_chars, domain_age]\n",
        "X = [[100, 10, 365], [50, 2, 730], [120, 15, 1]] # 1=phishing, 0=legit\n",
        "y = [1, 0, 1]\n",
        "# Logistic Regression\n",
        "lr_model = LogisticRegression()\n",
        "lr_model.fit(X, y)\n",
        "print(\"LR Prediction:\", lr_model.predict([[80, 5, 200]]))\n",
        "# Decision Tree\n",
        "dt_model = DecisionTreeClassifier()\n",
        "dt_model.fit(X, y)\n",
        "print(\"DT Prediction:\", dt_model.predict([[80, 5, 200]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-79o8xgq6XJw",
        "outputId": "d47d4bb3-31f6-4183-83eb-ad4e898bd1c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LR Prediction: [1]\n",
            "DT Prediction: [1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lab 4: Image Spam Detection with SVM\n",
        "\n",
        "AIM: Classify spam images using SVM.\n"
      ],
      "metadata": {
        "id": "Ex0zQsTn6b99"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lab 4: Image Spam Detection (using HOG features)\n",
        "from sklearn.svm import SVC\n",
        "from skimage.feature import hog\n",
        "import numpy as np\n",
        "# Example: HOG features from images (replace with real data)\n",
        "X = [np.random.rand(100) for _ in range(10)] # Simulated HOG features\n",
        "y = [1, 0, 1, 0, 1, 0, 0, 1, 0, 1] # 1=spam, 0=normal\n",
        "# Train SVM\n",
        "clf = SVC(kernel='linear')\n",
        "clf.fit(X, y)\n",
        "print(\"Prediction:\", clf.predict([np.random.rand(100)]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UApXjC096f-x",
        "outputId": "0a26addd-82f9-434e-9284-a86f8bc010e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: [1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lab 5: Malware Classification with Naive Bayes\n",
        "\n",
        "AIM: Classify malware families."
      ],
      "metadata": {
        "id": "YT04BjaC6l24"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lab 5: Naive Bayes for Malware\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "# Example: Features = [file_size, entropy, API_calls]\n",
        "X = [[5000, 6.2, 150], [2000, 5.1, 50], [8000, 7.0, 200]]\n",
        "y = [\"Trojan\", \"Benign\", \"Ransomware\"]\n",
        "# Train\n",
        "model = GaussianNB()\n",
        "model.fit(X, y)\n",
        "print(\"Predicted:\", model.predict([[6000, 6.5, 180]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCqp3iGG6noW",
        "outputId": "17bfb834-f768-41c9-e10b-209966d9873b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: ['Trojan']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lab 6: NLP for Spam Detection (BERT/Word2Vec)\n",
        "\n",
        "AIM: Spam detection using NLP."
      ],
      "metadata": {
        "id": "5J724pDT6uCN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lab 6: NLP Spam Detection (using BERT embeddings)\n",
        "!pip install transformers\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import torch\n",
        "# Load pre-trained BERT\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
        "# Example email\n",
        "inputs = tokenizer(\"Win a free iPhone!\", return_tensors=\"pt\")\n",
        "outputs = model(**inputs)\n",
        "print(\"Spam Probability:\", torch.sigmoid(outputs.logits[0,1]).item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-AjOkyM6opQ",
        "outputId": "7951ca02-84f2-4fe6-819f-54be69d9d86d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spam Probability: 0.43773379921913147\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lab 7: Keystroke Dynamics for Authentication\n",
        "\n",
        "AIM: Authenticate users via keystroke timing.\n"
      ],
      "metadata": {
        "id": "GbcuKueg61o4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lab 7: Keystroke Authentication\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# Features: [dwell_time, flight_time, ...]\n",
        "X = [[200, 150], [180, 120], [220, 180]] # User1=0, User2=1\n",
        "y = [0, 1, 0]\n",
        "# Train\n",
        "clf = RandomForestClassifier()\n",
        "clf.fit(X, y)\n",
        "print(\"Authenticated User:\", clf.predict([[190, 140]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJIfVwko64Ft",
        "outputId": "6e2f959a-6fcc-4deb-cdcc-c9d7f08ee378"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authenticated User: [0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lab 8: Facial Recognition with OpenCV\n",
        "\n",
        "AIM: Biometric authentication using facial recognition."
      ],
      "metadata": {
        "id": "Jh5lnt1u68-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lab 8: Face Recognition (using OpenCV)\n",
        "import cv2\n",
        "# Load pre-trained face detector\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "# Detect faces in an image\n",
        "img = cv2.imread(\"/content/drive/MyDrive/Colab Notebooks/AI in CS/IMG20230606120128 (2) (1).jpg\")\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
        "print(f\"Faces Detected: {len(faces)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IC_Nr0I648G",
        "outputId": "2481f70d-decc-4e97-dc7e-c17d5d472b88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Faces Detected: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lab 9: Fraud Detection with XGBoost\n",
        "\n",
        "AIM: Detect fraudulent transactions."
      ],
      "metadata": {
        "id": "y1DXB-vz7FJq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lab 9: Fraud Detection with XGBoost\n",
        "!pip install xgboost\n",
        "from xgboost import XGBClassifier\n",
        "# Example: [amount, time, location]\n",
        "X = [[1000, 12, 1], [20, 15, 0], [5000, 3, 1]] # 1=fraud, 0=legit\n",
        "y = [1, 0, 1]\n",
        "# Train\n",
        "model = XGBClassifier()\n",
        "model.fit(X, y)\n",
        "print(\"Fraud Prediction:\", model.predict([[2000, 2, 1]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjXtF0mt7GZs",
        "outputId": "bf26961f-6990-4b83-94ad-b698827bdd0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.0.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.15.3)\n",
            "Fraud Prediction: [1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lab 10: Cloud AI with IBM Watson\n",
        "\n",
        "AIM: Anomaly detection using IBM Watson."
      ],
      "metadata": {
        "id": "lSNcKNPh7LMK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "data = [[100], [110], [5000], [120], [130]]\n",
        "clf = IsolationForest(contamination=0.2)\n",
        "clf.fit(data)\n",
        "preds = clf.predict(data)\n",
        "\n",
        "for i, val in enumerate(data):\n",
        "    status = \"Anomaly\" if preds[i] == -1 else \"Normal\"\n",
        "    print(f\"Value: {val[0]} => {status}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUy8nQ0288Cj",
        "outputId": "c6150e2e-939f-483e-8fa6-14f23d4a5356"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Value: 100 => Normal\n",
            "Value: 110 => Normal\n",
            "Value: 5000 => Anomaly\n",
            "Value: 120 => Normal\n",
            "Value: 130 => Normal\n"
          ]
        }
      ]
    }
  ]
}