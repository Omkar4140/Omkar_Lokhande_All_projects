{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uB4f2h0qYbSo","executionInfo":{"status":"ok","timestamp":1716812243636,"user_tz":-330,"elapsed":1130,"user":{"displayName":"Omkar Lokhande","userId":"12029620098751607426"}},"outputId":"f32c4ccd-7d46-4a1f-bb07-cf63773eccc2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Average Rewards: 0.0\n"]}],"source":["import numpy as np\n","import random\n","import gym\n","\n","class SARSA:\n","    def __init__(self, env, alpha=0.1, gamma=0.99, epsilon=0.1, max_episodes=2000, max_steps=200):\n","        self.env = env\n","        self.alpha = alpha  # learning rate\n","        self.gamma = gamma  # discount factor\n","        self.epsilon = epsilon  # exploration-exploitation tradeoff\n","        self.max_episodes = max_episodes\n","        self.max_steps = max_steps\n","        self.q_table = np.zeros((env.observation_space.n, env.action_space.n))\n","\n","    def choose_action(self, state):\n","        if np.random.uniform(0, 1) < self.epsilon:\n","            return self.env.action_space.sample()  # Explore action space\n","        else:\n","            return np.argmax(self.q_table[state, :])  # Exploit learned values\n","\n","    def update_q_table(self, state, action, reward, next_state, next_action):\n","        predict = self.q_table[state, action]\n","        target = reward + self.gamma * self.q_table[next_state, next_action]\n","        self.q_table[state, action] += self.alpha * (target - predict)\n","\n","    def train(self):\n","        rewards = []\n","        for episode in range(self.max_episodes):\n","            state = self.env.reset()\n","            total_reward = 0\n","            action = self.choose_action(state)\n","            for step in range(self.max_steps):\n","                next_state, reward, done, _ = self.env.step(action)\n","                next_action = self.choose_action(next_state)\n","                self.update_q_table(state, action, reward, next_state, next_action)\n","                total_reward += reward\n","                state = next_state\n","                action = next_action\n","                if done:\n","                    break\n","            rewards.append(total_reward)\n","        return rewards\n","\n","# Create a grid world environment\n","env = gym.make(\"FrozenLake-v1\")\n","\n","# Create an instance of SARSA\n","sarsa_agent = SARSA(env)\n","\n","# Train SARSA\n","rewards = sarsa_agent.train()\n","\n","# Print average rewards\n","print(\"Average Rewards:\", np.mean(rewards))"]}]}